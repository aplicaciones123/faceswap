{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de Old1.0_DFL_Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aplicaciones123/faceswap/blob/master/Copia_de_Old1_0_DFL_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cKdTCuv4tXh"
      },
      "source": [
        "# Welcome to DFL-Colab!\n",
        "\n",
        "This is an adapted version of the DFL for Google Colab.\n",
        "\n",
        "\n",
        "# Overview\n",
        "*   Extractor works in full functionality.\n",
        "*   Training can work without preview.\n",
        "*   Merger works in full functionality.\n",
        "*   You can import/export workspace with your Google Drive.\n",
        "*   Import/export and another manipulations with workspace you can do in \"Manage workspace\" block\n",
        "*   Google Colab machine active for 12 hours. DFL-Colab makes a backup of your workspace in training mode.\n",
        "*   Google does not like long-term heavy calculations. Therefore, for training more than two sessions in a row, use two Google accounts. It is recommended to split your training over 2 accounts, but you can use one Google Drive account to store your workspace.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QZdL_pJHpkTE",
        "outputId": "4c1e2329-b0a0-4de3-fdb2-3c0c1b2a4b1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYtWMzOvLQ3s"
      },
      "source": [
        "## Prevent random disconnects\n",
        "\n",
        "This cell runs JS code to automatic reconnect to runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtClEMAMLVHw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96ca5a1b-9db5-4b40-f348-6e5918263163"
      },
      "source": [
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDg_jiQ9adQe"
      },
      "source": [
        "## Check GPU\n",
        "\n",
        "*   Google Colab can provide you with one of Tesla graphics cards: K80, T4, P4 or P100\n",
        "*   Here you can check the model of GPU before using DeepFaceLab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJe71S6gbzt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ede4e06-5006-4c6c-e61f-20bbf7151612"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jun  1 19:04:05 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffqS5OaCJHLi"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVn21kt40Gw"
      },
      "source": [
        "## Install or update DeepFaceLab\n",
        "\n",
        "* Install or update DeepFAceLab directly from Github\n",
        "* Requirements install is automatically\n",
        "* Automatically sets timer to prevent random disconnects\n",
        "* \"Download FFHQ\" option means to download high quality FFHQ dataset instead of CelebA. FFHQ takes up more memory, so it will take longer to download than CelebA. It is recommended to enable this option if you are doing pretrain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JG-f2WqT4fLK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "61d6bbd8-efd4-4a09-ac48-ce93d02f7309"
      },
      "source": [
        "#@title Install or update DeepFaceLab from Github\n",
        "\n",
        "Mode = \"install\" #@param [\"install\", \"update\"]\n",
        "Download_FFHQ = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "pretrain_link = \"https://github.com/chervonij/DFL-Colab/releases/download/\"\n",
        "pretrain_link = pretrain_link+\"pretrain_GenericFFHQ/pretrain_FFHQ.zip\" if Download_FFHQ else pretrain_link+\"pretrain-CelebA/pretrain_CelebA.zip\"\n",
        "\n",
        "from pathlib import Path\n",
        "if (Mode == \"install\"):\n",
        "  !git clone https://github.com/iperov/DeepFaceLab.git\n",
        "  %cd \"/content/DeepFaceLab\"\n",
        "  #!git checkout 9ad9728b4021d1dff62905cce03e2157d0c0868d\n",
        "  %cd \"/content\"\n",
        "\n",
        "  # fix linux warning\n",
        "  # /usr/lib/python3.6/multiprocessing/semaphore_tracker.py:143: UserWarning: semaphore_tracker: There appear to be 1 leaked semaphores to clean up at shutdown\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"rt\")\n",
        "  data = fin.read()\n",
        "  data = data.replace('if cache:', 'if False:')\n",
        "  fin.close()\n",
        "\n",
        "  fin = open(\"/usr/lib/python3.6/multiprocessing/semaphore_tracker.py\", \"wt\")\n",
        "  fin.write(data)\n",
        "  fin.close()\n",
        "else:\n",
        "  %cd /content/DeepFaceLab\n",
        "  !git pull\n",
        "\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install -r /content/DeepFaceLab/requirements-colab.txt\n",
        "!pip install --upgrade scikit-image\n",
        "!apt-get install cuda-10-0\n",
        "\n",
        "if not Path(\"/content/pretrain\").exists():\n",
        "  print(\"Downloading Pretrain faceset ... \")\n",
        "  !wget -q --no-check-certificate -r $pretrain_link -O /content/pretrain_faceset.zip\n",
        "  !mkdir /content/pretrain\n",
        "  !unzip -q /content/pretrain_faceset.zip -d /content/pretrain/\n",
        "  !rm /content/pretrain_faceset.zip\n",
        "\n",
        "if not Path(\"/content/pretrain_Q96\").exists():\n",
        "  print(\"Downloading Q96 pretrained model ...\")\n",
        "  !wget -q --no-check-certificate -r 'https://github.com/chervonij/DFL-Colab/releases/download/Q96_model_pretrained/Q96_model_pretrained.zip' -O /content/pretrain_Q96.zip\n",
        "  !mkdir /content/pretrain_Q96\n",
        "  !unzip -q /content/pretrain_Q96.zip -d /content/pretrain_Q96/\n",
        "  !rm /content/pretrain_Q96.zip\n",
        "\n",
        "if not Path(\"/content/workspace\").exists():\n",
        "  !mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model  \n",
        "\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"\\nDone!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepFaceLab'...\n",
            "remote: Enumerating objects: 8018, done.\u001b[K\n",
            "remote: Total 8018 (delta 0), reused 0 (delta 0), pack-reused 8018\u001b[K\n",
            "Receiving objects: 100% (8018/8018), 823.29 MiB | 37.43 MiB/s, done.\n",
            "Resolving deltas: 100% (5152/5152), done.\n",
            "Checking out files: 100% (211/211), done.\n",
            "/content/DeepFaceLab\n",
            "/content\n",
            "Found existing installation: tensorflow 2.8.2+zzzcolab20220527125636\n",
            "Uninstalling tensorflow-2.8.2+zzzcolab20220527125636:\n",
            "  Successfully uninstalled tensorflow-2.8.2+zzzcolab20220527125636\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 1)) (4.64.0)\n",
            "Collecting numpy==1.19.3\n",
            "  Downloading numpy-1.19.3-cp37-cp37m-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 3)) (2.8.1)\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 60.3 MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.1.0.25\n",
            "  Downloading opencv_python-4.1.0.25-cp37-cp37m-manylinux1_x86_64.whl (26.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.6 MB 43.9 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.1.17\n",
            "  Downloading ffmpeg_python-0.1.17-py3-none-any.whl (20 kB)\n",
            "Collecting scikit-image==0.14.2\n",
            "  Downloading scikit_image-0.14.2-cp37-cp37m-manylinux1_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/DeepFaceLab/requirements-colab.txt (line 8)) (1.4.1)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tensorflow-gpu==2.4.0\n",
            "  Downloading tensorflow_gpu-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 16 kB/s \n",
            "\u001b[?25hCollecting tf2onnx==1.9.3\n",
            "  Downloading tf2onnx-1.9.3-py3-none-any.whl (435 kB)\n",
            "\u001b[K     |████████████████████████████████| 435 kB 72.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0->-r /content/DeepFaceLab/requirements-colab.txt (line 4)) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from ffmpeg-python==0.1.17->-r /content/DeepFaceLab/requirements-colab.txt (line 6)) (0.16.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: dask[array]>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (2.12.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (2.6.3)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: cloudpickle>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (1.1.0)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 25.3 MB/s \n",
            "\u001b[?25hCollecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 77.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (1.1.2)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (3.17.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (0.37.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (2.8.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tf2onnx==1.9.3->-r /content/DeepFaceLab/requirements-colab.txt (line 11)) (2.23.0)\n",
            "Collecting onnx>=1.4.1\n",
            "  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 54.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[array]>=1.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (0.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->scikit-image==0.14.2->-r /content/DeepFaceLab/requirements-colab.txt (line 7)) (3.0.9)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx==1.9.3->-r /content/DeepFaceLab/requirements-colab.txt (line 11)) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx==1.9.3->-r /content/DeepFaceLab/requirements-colab.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx==1.9.3->-r /content/DeepFaceLab/requirements-colab.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tf2onnx==1.9.3->-r /content/DeepFaceLab/requirements-colab.txt (line 11)) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu==2.4.0->-r /content/DeepFaceLab/requirements-colab.txt (line 10)) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->-r /content/DeepFaceLab/requirements-colab.txt (line 3)) (21.3)\n",
            "Building wheels for collected packages: wrapt\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68720 sha256=11d7bc6876aa468713f5c3b0c1d44eca0f0f27b8ab41fb06952a6055f4cfa148\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
            "Successfully built wrapt\n",
            "Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, onnx, h5py, gast, flatbuffers, tf2onnx, tensorflow-gpu, scikit-image, opencv-python, ffmpeg-python, colorama\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.8.0\n",
            "    Uninstalling tensorflow-estimator-2.8.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.8.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.3\n",
            "    Uninstalling gast-0.5.3:\n",
            "      Successfully uninstalled gast-0.5.3\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 2.0\n",
            "    Uninstalling flatbuffers-2.0:\n",
            "      Successfully uninstalled flatbuffers-2.0\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, which is not installed.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.3 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 colorama-0.4.4 ffmpeg-python-0.1.17 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.3 onnx-1.11.0 opencv-python-4.1.0.25 scikit-image-0.14.2 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.0 tf2onnx-1.9.3 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.14.2)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.19.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.19.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.14.2\n",
            "    Uninstalling scikit-image-0.14.2:\n",
            "      Successfully uninstalled scikit-image-0.14.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-image-0.19.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "cuda-10-0 is already the newest version (10.0.130-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Downloading Pretrain faceset ... \n",
            "Downloading Q96 pretrained model ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              " function ClickConnect(){\n",
              "   btn = document.querySelector(\"colab-connect-button\")\n",
              "   if (btn != null){\n",
              "     console.log(\"Click colab-connect-button\"); \n",
              "     btn.click() \n",
              "     }\n",
              "   \n",
              "   btn = document.getElementById('ok')\n",
              "   if (btn != null){\n",
              "     console.log(\"Click reconnect\"); \n",
              "     btn.click() \n",
              "     }\n",
              "  }\n",
              "  \n",
              "setInterval(ClickConnect,60000)\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqwOlJG4MdLC"
      },
      "source": [
        "## Manage workspace\n",
        "\n",
        "\n",
        "\n",
        "*   You can import/export workspace or individual data, like model files with Google Drive\n",
        "*   Also, you can use HFS (HTTP Fileserver) for directly import/export you workspace from your computer\n",
        "*   You can clear all workspace or delete part of it\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4w_sUzgOQmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a50f9fa8-3a05-4db5-a184-e33e93b80585"
      },
      "source": [
        "#@title Import from Drive\n",
        "\n",
        "Mode = \"data_dst\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"models\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  unzip_cmd=\" -q \"+Archive_name\n",
        "  \n",
        "  %cd $path\n",
        "  copy_cmd = \"/content/drive/My\\ Drive/\"+Archive_name+\" \"+path\n",
        "  !cp $copy_cmd\n",
        "  !unzip $unzip_cmd    \n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "  \n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/workspace\n",
            "replace data_src.mp4? [y]es, [n]o, [A]ll, [N]one, [r]ename: Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqjy0itfqySt"
      },
      "source": [
        "#%cd /\n",
        "#!unzip /content/drive/MyDrive/1_hd.zip -d /"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zJE7ryG10IR"
      },
      "source": [
        "#!zip /content/drive/MyDrive/1_BackupSAEHD_Beast1.zip -r /content/drive/MyDrive/DFL_SAEHD_Beast1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hAMjDZ-tQYC"
      },
      "source": [
        "#!rm /content/workspace/data_src/aligned_HD/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y3WfuwoNXqC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e333188-43ef-40a6-ea00-9853d5176564"
      },
      "source": [
        "#@title Export to Drive { form-width: \"30%\" }\n",
        "Mode = \"workspace\" #@param [\"workspace\", \"data_src\", \"data_dst\", \"data_src aligned\", \"data_dst aligned\", \"merged\", \"merged_mask\", \"models\", \"result video\", \"result_mask video\"]\n",
        "Archive_name = \"workspace.zip\" #@param {type:\"string\"}\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "def zip_and_copy(path, mode):\n",
        "  zip_cmd=\"-r -q \"+Archive_name+\" \"\n",
        "  \n",
        "  %cd $path\n",
        "  zip_cmd+=mode\n",
        "  !zip $zip_cmd\n",
        "  copy_cmd = \" \"+Archive_name+\"  /content/drive/My\\ Drive/\"\n",
        "  !cp $copy_cmd\n",
        "  !rm $Archive_name\n",
        "\n",
        "if Mode == \"workspace\":\n",
        "  zip_and_copy(\"/content\", \"workspace\")\n",
        "elif Mode == \"data_src\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_src\")\n",
        "elif Mode == \"data_dst\":\n",
        "  zip_and_copy(\"/content/workspace\", \"data_dst\")\n",
        "elif Mode == \"data_src aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_src\", \"aligned\")\n",
        "elif Mode == \"data_dst aligned\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"aligned\")\n",
        "elif Mode == \"merged\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged\")\n",
        "elif Mode == \"merged_mask\":\n",
        "  zip_and_copy(\"/content/workspace/data_dst\", \"merged_mask\")\n",
        "elif Mode == \"models\":\n",
        "  zip_and_copy(\"/content/workspace\", \"model\")\n",
        "elif Mode == \"result video\":\n",
        "  !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/\n",
        "  \n",
        "print(\"Done!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "\n",
            "zip error: Nothing to do! (try: zip -r -q workspace.zip . -i workspace)\n",
            "cp: cannot stat 'workspace.zip': No such file or directory\n",
            "rm: cannot remove 'workspace.zip': No such file or directory\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hIvJtxwTGcb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V1sc7rxNKLO"
      },
      "source": [
        "#@title Export to URL\n",
        "URL = \"http://\" #@param {type:\"string\"}\n",
        "Mode = \"upload workspace\" #@param [\"upload workspace\", \"upload data_src\", \"upload data_dst\", \"upload data_src aligned\", \"upload data_dst aligned\", \"upload merged\", \"upload model\", \"upload result video\"]\n",
        "\n",
        "cmd_zip = \"zip -r -q \"\n",
        "\n",
        "def run_cmd(zip_path, curl_url):\n",
        "  cmd_zip = \"zip -r -q \"+zip_path\n",
        "  cmd_curl = \"curl --silent -F \"+curl_url+\" -D out.txt > /dev/null\"\n",
        "  !$cmd_zip\n",
        "  !$cmd_curl\n",
        "\n",
        "\n",
        "if Mode == \"upload workspace\":\n",
        "  %cd \"/content\"\n",
        "  run_cmd(\"workspace.zip workspace/\",\"'data=@/content/workspace.zip' \"+URL)\n",
        "elif Mode == \"upload data_src\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src.zip data_src/\", \"'data=@/content/workspace/data_src.zip' \"+URL)\n",
        "elif Mode == \"upload data_dst\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst.zip data_dst/\", \"'data=@/content/workspace/data_dst.zip' \"+URL)\n",
        "elif Mode == \"upload data_src aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_src_aligned.zip data_src/aligned\", \"'data=@/content/workspace/data_src_aligned.zip' \"+URL )\n",
        "elif Mode == \"upload data_dst aligned\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"data_dst_aligned.zip data_dst/aligned/\", \"'data=@/content/workspace/data_dst_aligned.zip' \"+URL)\n",
        "elif Mode == \"upload merged\":\n",
        "  %cd \"/content/workspace/data_dst\"\n",
        "  run_cmd(\"merged.zip merged/\",\"'data=@/content/workspace/data_dst/merged.zip' \"+URL )\n",
        "elif Mode == \"upload model\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"model.zip model/\", \"'data=@/content/workspace/model.zip' \"+URL)\n",
        "elif Mode == \"upload result video\":\n",
        "  %cd \"/content/workspace\"\n",
        "  run_cmd(\"result.zip result.mp4\", \"'data=@/content/workspace/result.zip' \"+URL)\n",
        "  \n",
        "  \n",
        "!rm *.zip\n",
        "\n",
        "%cd \"/content\"\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ta6ue_UGMkki"
      },
      "source": [
        "#@title Delete and recreate\n",
        "Mode = \"Delete and recreate workspace\" #@param [\"Delete and recreate workspace\", \"Delete models\", \"Delete data_src\", \"Delete data_src aligned\", \"Delete data_src video\", \"Delete data_dst\", \"Delete data_dst aligned\", \"Delete merged frames\"]\n",
        "\n",
        "%cd \"/content\" \n",
        "\n",
        "if Mode == \"Delete and recreate workspace\":\n",
        "  cmd = \"rm -r /content/workspace ; mkdir /content/workspace; mkdir /content/workspace/data_src; mkdir /content/workspace/data_src/aligned; mkdir /content/workspace/data_dst; mkdir /content/workspace/data_dst/aligned; mkdir /content/workspace/model\"  \n",
        "elif Mode == \"Delete models\":\n",
        "  cmd = \"rm -r /content/workspace/model/*\"\n",
        "elif Mode == \"Delete data_src\":\n",
        "  cmd = \"rm /content/workspace/data_src/*.png || rm -r /content/workspace/data_src/*.jpg\"\n",
        "elif Mode == \"Delete data_src aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_src/aligned/*\"\n",
        "elif Mode == \"Delete data_src video\":\n",
        "  cmd = \"rm -r /content/workspace/data_src.*\"\n",
        "elif Mode == \"Delete data_dst\":\n",
        "  cmd = \"rm /content/workspace/data_dst/*.png || rm /content/workspace/data_dst/*.jpg\"\n",
        "elif Mode == \"Delete data_dst aligned\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/aligned/*\"\n",
        "elif Mode == \"Delete merged frames\":\n",
        "  cmd = \"rm -r /content/workspace/data_dst/merged; rm -r /content/workspace/data_dst/merged_mask\"\n",
        "  \n",
        "!$cmd\n",
        "print(\"Done!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUNVcbujhm00"
      },
      "source": [
        "## Extract, sorting and faceset tools\n",
        "* Extract frames for SRC or DST video.\n",
        "* Denoise SRC or DST video. \"Factor\" param set intesity of denoising\n",
        "* Detect and align faces. If you need, you can get frames with debug landmarks.\n",
        "* Export workspace to Google Drive after extract and sort it manually (In \"Manage Workspace\" block)\n",
        "* You can enhance your facesets with DFL FacesetEnhancer.\n",
        "* Resize faceset to your model resolution. Since Colab doesn't have a powerful CPU, resizing samples during training increases iteration time. Faceset resize reduces iteration time by about 2x times. Don't forget to keep save original faceset on your PC.\n",
        "* Pack or unpack facesets with DFL packing tool.\n",
        "* Apply or remove trained XSeg model to the extracted faces.\n",
        "* Recommended for use, Generic XSeg model for auto segmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwJEbz5Nhot0",
        "outputId": "24143561-002a-4041-e8b3-0a899c409f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Extract frames\n",
        "Video = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "%cd \"/content\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed extract-video\"\n",
        "\n",
        "if Video == \"data_dst\":\n",
        "  cmd+= \" --input-file workspace/data_dst.* --output-dir workspace/data_dst/\"\n",
        "else:\n",
        "  cmd+= \" --input-file workspace/data_src.* --output-dir workspace/data_src/\"\n",
        "  \n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "[0] Enter FPS ( ?:help ) : 0\n",
            "0\n",
            "[png] Output image format ( png/jpg ?:help ) : png\n",
            "png\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/workspace/data_dst.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41isom\n",
            "    creation_time   : 2022-01-14T07:04:11.000000Z\n",
            "    title           : result\n",
            "    artist          : VideoProc\n",
            "    comment         : result\n",
            "  Duration: 00:10:00.13, start: 0.000000, bitrate: 5506 kb/s\n",
            "    Stream #0:0(und): Video: h264 (Constrained Baseline) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 5372 kb/s, 30 fps, 30 tbr, 30k tbn, 60 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-05-28T10:51:25.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : AVC Coding\n",
            "    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 131 kb/s (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-05-28T10:51:25.000000Z\n",
            "      handler_name    : SoundHandler\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (h264 (native) -> png (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/workspace/data_dst/%5d.png':\n",
            "  Metadata:\n",
            "    major_brand     : mp42\n",
            "    minor_version   : 0\n",
            "    compatible_brands: mp41isom\n",
            "    comment         : result\n",
            "    title           : result\n",
            "    artist          : VideoProc\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0(und): Video: png, rgb24, 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n",
            "    Metadata:\n",
            "      creation_time   : 2022-05-28T10:51:25.000000Z\n",
            "      handler_name    : VideoHandler\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame=10519 fps=8.3 q=-0.0 Lsize=N/A time=00:05:50.63 bitrate=N/A speed=0.278x    \n",
            "video:18712145kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFmPo0s2lTil",
        "outputId": "10f2467c-1403-46e5-b4b6-9fb905414044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Denoise frames\n",
        "Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "Factor = 1 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py videoed denoise-image-sequence --input-dir workspace/\"+Data+\" --factor \"+str(Factor)\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "[7] Denoise factor? ( 1-20 ) : 1\n",
            "1\n",
            "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '/content/workspace/data_src/%6d.png':\n",
            "  Duration: 00:02:09.20, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: png, rgb24(pc), 512x410 [SAR 1:1 DAR 256:205], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "Stream mapping:\n",
            "  Stream #0:0 (png) -> hqdn3d\n",
            "  hqdn3d -> Stream #0:0 (png)\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, image2, to '/content/workspace/data_src/%6d.png':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: png, rgb24, 512x410 [SAR 1:1 DAR 256:205], q=2-31, 200 kb/s, 25 fps, 25 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 png\n",
            "frame= 3230 fps= 61 q=-0.0 Lsize=N/A time=00:02:09.20 bitrate=N/A speed=2.43x    \n",
            "video:517730kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmq0Sj2bmq7d",
        "outputId": "c0d39587-a925-47b4-f264-0f71abc10529",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Detect faces\n",
        "Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "Detector = \"S3FD\" #@param [\"S3FD\", \"S3FD (whole face)\"]\n",
        "Debug = False #@param {type:\"boolean\"}\n",
        "\n",
        "detect_type = \"s3fd\"\n",
        "dbg = \" --output-debug\" if Debug else \" --no-output-debug\"\n",
        "\n",
        "folder = \"workspace/\"+Data\n",
        "folder_aligned = folder+\"/aligned\"\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py extract --input-dir \"+folder+\" --output-dir \"+folder_aligned\n",
        "cmd+=\" --detector \"+detect_type+\" --force-gpu-idxs 0\"+dbg\n",
        "\n",
        "if \"whole face\" in Detector:\n",
        "  cmd+=\" --face-type whole_face\" \n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "[wf] Face type ( f/wf/head ?:help ) : f\n",
            "f\n",
            "[0] Max number of faces from image ( ?:help ) : ?\n",
            "If you extract a src faceset that has frames with a large number of faces, it is advisable to set max faces to 3 to speed up extraction. 0 - unlimited\n",
            "[0] Max number of faces from image ( ?:help ) : 3\n",
            "3\n",
            "[512] Image size ( 256-2048 ?:help ) : 512\n",
            "512\n",
            "[90] Jpeg quality ( 1-100 ?:help ) : 90\n",
            "90\n",
            "Extracting faces...\n",
            "Running on Tesla T4\n",
            " 48% 5011/10519 [39:15<43:08,  2.13it/s]q\n",
            " 51% 5316/10519 [41:29<40:36,  2.14it/s]Traceback (most recent call last):\n",
            "  File \"DeepFaceLab/main.py\", line 343, in <module>\n",
            "    arguments.func(arguments)\n",
            "  File \"DeepFaceLab/main.py\", line 45, in process_extract\n",
            "    force_gpu_idxs          = [ int(x) for x in arguments.force_gpu_idxs.split(',') ] if arguments.force_gpu_idxs is not None else None,\n",
            "  File \"/content/DeepFaceLab/mainscripts/Extractor.py\", line 827, in main\n",
            "    device_config=device_config).run()\n",
            "  File \"/content/DeepFaceLab/core/joblib/SubprocessorBase.py\", line 266, in run\n",
            "    io.process_messages(self.io_loop_sleep_time)\n",
            "  File \"/content/DeepFaceLab/core/interact/interact.py\", line 188, in process_messages\n",
            "    self.on_process_messages(sleep_time)\n",
            "  File \"/content/DeepFaceLab/core/interact/interact.py\", line 572, in on_process_messages\n",
            "    time.sleep(sleep_time)\n",
            "KeyboardInterrupt\n",
            " 51% 5316/10519 [41:29<40:36,  2.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRNxUFE6p6Eu"
      },
      "source": [
        "#@title Sort aligned\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "sort_type = \"hist\" #@param [\"blur\", \"motion-blur\", \"face-yaw\", \"face-pitch\", \"face-source-rect-size\", \"hist\", \"hist-dissim\", \"brightness\", \"hue\", \"black\", \"origname\", \"oneface\", \"final-by-blur\", \"final-by-size\", \"absdiff\"]\n",
        "\n",
        "cmd = \"DeepFaceLab/main.py sort --input-dir workspace/\"+Data+\"/aligned --by \"+sort_type\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5MbnVDyXkP7"
      },
      "source": [
        "#@title Faceset Enhancer\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "data_path = \"/content/workspace/\"+Data+\"/aligned\"\n",
        "cmd = \"/content/DeepFaceLab/main.py facesettool enhance --input-dir \"+data_path\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyg5SREuMx8Q"
      },
      "source": [
        "#@title Resize faceset\n",
        "Data = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "\n",
        "cmd = \"/content/DeepFaceLab/main.py facesettool resize --input-dir /content/workspace/\" + \\\n",
        "      f\"{Data}/aligned\"\n",
        "\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypLfPUNHZNEp"
      },
      "source": [
        "#@title Pack/Unpack aligned faceset\n",
        "\n",
        "Folder = \"data_src\" #@param [\"data_src\", \"data_dst\"]\n",
        "Mode = \"unpack\" #@param [\"pack\", \"unpack\"]\n",
        "\n",
        "cmd = \"/content/DeepFaceLab/main.py util --input-dir /content/workspace/\" + \\\n",
        "      f\"{Folder}/aligned --{Mode}-faceset\"\n",
        "\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VVvtoBMGnrA",
        "outputId": "9604df3f-7a6b-4506-965d-3bf018506093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Apply or remove XSeg mask to the faces\n",
        "Mode = \"Apply mask\" #@param [\"Apply mask\", \"Remove mask\"]\n",
        "Data = \"data_dst\" #@param [\"data_src\", \"data_dst\"]\n",
        "GenericXSeg = True #@param {type:\"boolean\"}\n",
        "\n",
        "from pathlib import Path\n",
        "mode_arg = 'apply' if Mode == \"Apply mask\" else 'remove'\n",
        "\n",
        "if GenericXSeg and not Path('/content/GenericXSeg').exists():\n",
        "  print('Downloading Generic XSeg model ... ')\n",
        "  xseg_link = 'https://github.com/chervonij/DFL-Colab/releases/download/GenericXSeg/GenericXSeg.zip'\n",
        "  !mkdir /content/GenericXSeg\n",
        "  !wget -q --no-check-certificate -r $xseg_link -O /content/GenericXSeg.zip\n",
        "  !unzip -q /content/GenericXSeg.zip -d /content/GenericXSeg/\n",
        "  !rm /content/GenericXSeg.zip\n",
        "\n",
        "main_path = '/content/DeepFaceLab/main.py'\n",
        "data_path = f'/content/workspace/{Data}/aligned'\n",
        "model_path = '/content/workspace/model' if not GenericXSeg else '/content/GenericXSeg'\n",
        "\n",
        "cmd = f'{main_path} xseg {mode_arg} --input-dir {data_path} '\n",
        "cmd += f'--model-dir {model_path}' if mode_arg == 'apply' else ''\n",
        "\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying trained XSeg model to aligned/ folder.\n",
            "\n",
            "Choose one GPU idx.\n",
            "\n",
            "[CPU] : CPU\n",
            "  [0] : Tesla T4\n",
            "\n",
            "[0] Which GPU index to choose? : 0\n",
            "0\n",
            "\n",
            "Processing: 100% 5295/5295 [03:53<00:00, 22.70it/s]\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTuyUxgdLA13"
      },
      "source": [
        "## Train model\n",
        "\n",
        "* Choose your model type, but SAEHD is recommend for everyone\n",
        "* Set model options on output field\n",
        "* You can see preview manually, if go to model folder in filemanager and double click on preview.jpg file\n",
        "* Your workspace will be archived and upload to mounted Drive after 11 hours from start session\n",
        "* If you select \"Backup_every_hour\" option, your workspace will be backed up every hour.\n",
        "* Also, you can export your workspace manually in \"Manage workspace\" block\n",
        "* \"Silent_Start\" option provides to automatically start with best GPU and last used model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Kya-PJLDhv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e26b71d0-7880-4ac3-8bea-8214e21ca810"
      },
      "source": [
        "#@title Training\n",
        "Model = \"XSeg\" #@param [\"SAEHD\", \"AMP\", \"Quick96\", \"XSeg\"]\n",
        "Model_dir = \"/content/drive/MyDrive/DFL_SAEHD_Beast\" #@param {type:\"string\"}\n",
        "Force_name = \"new\" #@param {type:\"string\"} \n",
        "Dst_aligned = \"Default\" #@param [ \"Pretrain\", \"Default\" ] \n",
        "Src_aligned = \"Default\" #@param [ \"Custom patch\", \"Default\" ] \n",
        "Custom_dir_src_aligned = \"workspace/data_src/aligned_4k\" #@param {type:\"string\"} \n",
        "#Model = \"SAEHD\" #@param [\"SAEHD\", \"SAE\", \"Quick96\", \"H128\", \"LIAEF128\", \"DF\", \"AVATAR\", \"DEV_FANSEG\"]\n",
        "Backup_every_hour = True #@param {type:\"boolean\"}\n",
        "\n",
        "%cd /content\n",
        "\n",
        "#Mount Google Drive as folder\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import psutil, os, time\n",
        "\n",
        "p = psutil.Process(os.getpid())\n",
        "uptime = time.time() - p.create_time()\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  if not os.path.exists('workspace.zip'):\n",
        "    print(\"Creating workspace archive ...\")\n",
        "    !zip -r -q workspace.zip workspace\n",
        "    print(\"Archive created!\")\n",
        "  else:\n",
        "    print(\"Archive exist!\")\n",
        "\n",
        "if (Backup_every_hour):\n",
        "  print(\"Time to end session: \"+str(round((43200-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(3600)\n",
        "  backup_cmd = \" --execute-program -\"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace/model'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "elif (round(39600-uptime) > 0):\n",
        "  print(\"Time to backup: \"+str(round((39600-uptime)/3600))+\" hours\")\n",
        "  backup_time = str(round(39600-uptime))\n",
        "  backup_cmd = \" --execute-program \"+backup_time+\" \\\"import os; os.system('zip -r -q workspace.zip workspace'); os.system('cp /content/workspace.zip /content/drive/My\\ Drive/'); print('Backed up!') \\\"\" \n",
        "else:\n",
        "  print(\"Session expires in less than an hour.\")\n",
        "  backup_cmd = \"\"\n",
        "\n",
        "if Dst_aligned == \"Pretrain\":\n",
        "  Dir_dst_aligned = \"pretrain\"\n",
        "elif Dst_aligned == \"Default\":\n",
        "  Dir_dst_aligned = \"workspace/data_dst/aligned\" \n",
        "\n",
        "if Src_aligned == \"Custom patch\":\n",
        "  Dir_src_aligned = Custom_dir_src_aligned\n",
        "elif Src_aligned == \"Default\":\n",
        "  Dir_src_aligned = \"workspace/data_src/aligned\" \n",
        "    \n",
        "cmd = \"DeepFaceLab/main.py train --training-data-src-dir \" + Dir_src_aligned + \" --training-data-dst-dir \" + Dir_dst_aligned + \" --pretraining-data-dir pretrain --model-dir \" + Model_dir + \" --model \"+Model + \" --force-model-name \" + Force_name + \" --force-gpu-idxs 0\"\n",
        "  \n",
        "if (backup_cmd != \"\"):\n",
        "  train_cmd = (cmd+backup_cmd)\n",
        "else:\n",
        "  train_cmd = (cmd)\n",
        "\n",
        "!python $train_cmd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Creating workspace archive ...\n",
            "\n",
            "\n",
            "zip error: Interrupted (aborting)\n",
            "Archive created!\n",
            "Time to end session: 10 hours\n",
            "Running trainer.\n",
            "\n",
            "\n",
            "Model first run.\n",
            "[wf] Face type ( h/mf/f/wf/head ?:help ) : f\n",
            "f\n",
            "[4] Batch_size ( 2-16 ?:help ) : 8\n",
            "8\n",
            "[n] Enable pretraining mode ( y/n ) : n\n",
            "Loading samples: 100% 3230/3230 [00:33<00:00, 96.43it/s]\n",
            "Loading samples: 100% 5295/5295 [00:27<00:00, 195.66it/s]\n",
            "Filtering: 100% 8525/8525 [00:23<00:00, 365.17it/s]\n",
            "Filtering: 100% 8525/8525 [00:23<00:00, 365.60it/s]\n",
            "Using 8525 xseg labeled samples.\n",
            "========= Model Summary =========\n",
            "==                             ==\n",
            "==        Model name: XSeg     ==\n",
            "==                             ==\n",
            "== Current iteration: 0        ==\n",
            "==                             ==\n",
            "==------- Model Options -------==\n",
            "==                             ==\n",
            "==         face_type: f        ==\n",
            "==          pretrain: False    ==\n",
            "==        batch_size: 8        ==\n",
            "==                             ==\n",
            "==-------- Running On ---------==\n",
            "==                             ==\n",
            "==      Device index: 0        ==\n",
            "==              Name: Tesla T4 ==\n",
            "==              VRAM: 13.64GB  ==\n",
            "==                             ==\n",
            "=================================\n",
            "Starting. Press \"Enter\" to stop training and save model.\n",
            "\n",
            "Trying to do the first iteration. If an error occurs, reduce the model parameters.\n",
            "\n",
            "[21:01:27][#000002][0424ms][0.8656]\n",
            "[21:25:54][#002346][0453ms][0.1017]\n",
            "[21:50:54][#004657][0420ms][0.0492]\n",
            "[22:00:52][#005587][0706ms][0.0501]Backed up!\n",
            "[22:15:54][#007040][0402ms][0.0401]\n",
            "[22:40:53][#009477][0425ms][0.0356]\n",
            "[23:00:52][#011423][0647ms][0.0151]Backed up!\n",
            "[23:05:54][#011911][0432ms][0.0325]\n",
            "[23:30:54][#014353][0605ms][0.0306]\n",
            "[23:55:54][#016790][0729ms][0.0293]\n",
            "[00:00:52][#017277][0589ms][0.0383]Backed up!\n",
            "[00:11:03][#018267][0714ms][0.0322]\n",
            "[00:12:30][#018407][0674ms][0.0254]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avAcSL_uvtq_"
      },
      "source": [
        "## Merge frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3Y8K22Sv9Gn"
      },
      "source": [
        "#@title Merge\n",
        "Model = \"SAEHD\" #@param [\"SAEHD\", \"AMP\", \"Quick96\" ]\n",
        "Model_dir = \"/content/drive/MyDrive/DFL_SAEHD_Beast1\" #@param {type:\"string\"}\n",
        "force_name = \"new\" #@param {type:\"string\"} \n",
        "cmd = \"DeepFaceLab/main.py merge --input-dir workspace/data_dst --output-dir workspace/data_dst/merged --output-mask-dir workspace/data_dst/merged_mask --aligned-dir workspace/data_dst/aligned --model-dir \" + Model_dir + \" --model \"+Model + \" --force-model-name \" + force_name + \" --cpu-only\"\n",
        "\n",
        "%cd \"/content\"\n",
        "!python $cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNeGfiZpxlnz"
      },
      "source": [
        "#@title Get result video \n",
        "Mode = \"result video\" #@param [\"result video\", \"result_mask video\"]\n",
        "Copy_to_Drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if Mode == \"result video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged --output-file workspace/result.mp4 --reference-file workspace/data_dst.mp4 --include-audio\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result.mp4 /content/drive/My\\ Drive/\n",
        "elif Mode == \"result_mask video\":\n",
        "  !python DeepFaceLab/main.py videoed video-from-sequence --input-dir workspace/data_dst/merged_mask --output-file workspace/result_mask.mp4 --reference-file workspace/data_dst.mp4\n",
        "  if Copy_to_Drive:\n",
        "    !cp /content/workspace/result_mask.mp4 /content/drive/My\\ Drive/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}